![](images/HeaderPic.png "Microsoft Cloud Workshops")

<div class="MCWHeader1">
Intelligent vending machines
</div>

<div class="MCWHeader2">
Whiteboard design session trainer guide
</div>

<div class="MCWHeader3">
March 2018
</div>



Information in this document, including URL and other Internet Web site references, is subject to change without notice. Unless otherwise noted, the example companies, organizations, products, domain names, e-mail addresses, logos, people, places, and events depicted herein are fictitious, and no association with any real company, organization, product, domain name, e-mail address, logo, person, place or event is intended or should be inferred. Complying with all applicable copyright laws is the responsibility of the user. Without limiting the rights under copyright, no part of this document may be reproduced, stored in or introduced into a retrieval system, or transmitted in any form or by any means (electronic, mechanical, photocopying, recording, or otherwise), or for any purpose, without the express written permission of Microsoft Corporation.

Microsoft may have patents, patent applications, trademarks, copyrights, or other intellectual property rights covering subject matter in this document. Except as expressly provided in any written license agreement from Microsoft, the furnishing of this document does not give you any license to these patents, trademarks, copyrights, or other intellectual property.

The names of manufacturers, products, or URLs are provided for informational purposes only and Microsoft makes no representations and warranties, either expressed, implied, or statutory, regarding these manufacturers or the use of the products with any Microsoft technologies. The inclusion of a manufacturer or product does not imply endorsement of Microsoft of the manufacturer or product. Links may be provided to third party sites. Such sites are not under the control of Microsoft and Microsoft is not responsible for the contents of any linked site or any link contained in a linked site, or any changes or updates to such sites. Microsoft is not responsible for webcasting or any other form of transmission received from any linked site. Microsoft is providing these links to you only as a convenience, and the inclusion of any link does not imply endorsement of Microsoft of the site or the products contained therein.
© 2018 Microsoft Corporation. All rights reserved.

Microsoft and the trademarks listed at https://www.microsoft.com/en-us/legal/intellectualproperty/Trademarks/Usage/General.aspx are trademarks of the Microsoft group of companies. All other trademarks are property of their respective owners.

**Contents**
<!-- TOC -->

- [Trainer information](#trainer-information)
    - [Role of the trainer](#role-of-the-trainer)
    - [Whiteboard design session flow](#whiteboard-design-session-flow)
    - [Before the whiteboard design session: How to prepare](#before-the-whiteboard-design-session-how-to-prepare)
    - [During the whiteboard design session: Tips for an effective whiteboard design session](#during-the-whiteboard-design-session-tips-for-an-effective-whiteboard-design-session)
- [Intelligent vending machines whiteboard design session student guide](#intelligent-vending-machines-whiteboard-design-session-student-guide)
    - [Abstract and learning objectives](#abstract-and-learning-objectives)
    - [Step 1: Review the customer case study](#step-1-review-the-customer-case-study)
        - [Customer situation](#customer-situation)
        - [Customer needs](#customer-needs)
        - [Customer objections](#customer-objections)
        - [Infographic for common scenarios](#infographic-for-common-scenarios)
    - [Step 2: Design a proof of concept solution](#step-2-design-a-proof-of-concept-solution)
    - [Step 3: Present the solution](#step-3-present-the-solution)
    - [Additional references](#additional-references)
- [Intelligent vending machines whiteboard design session trainer guide](#intelligent-vending-machines-whiteboard-design-session-trainer-guide)
    - [Step 1: Review the customer case study](#step-1-review-the-customer-case-study-1)
    - [Step 2: Design a proof of concept solution](#step-2-design-a-proof-of-concept-solution-1)
    - [Step 3: Present the solution](#step-3-present-the-solution-1)
    - [Wrap-up](#wrap-up)
    - [Preferred target audience](#preferred-target-audience)
    - [Preferred solution](#preferred-solution)
    - [Checklist of preferred objection handling](#checklist-of-preferred-objection-handling)
    - [Customer quote (to be read back to the attendees at the end)](#customer-quote-to-be-read-back-to-the-attendees-at-the-end)

<!-- /TOC -->


# Trainer information

Thank you for taking time to support the whiteboard design sessions as a trainer!

## Role of the trainer

An amazing trainer:

-   Creates a safe environment in which learning can take place.

-   Stimulates the participant's thinking.

-   Involves the participant in the learning process.

-   Manages the learning process (on time, on topic, and adjusting to benefit participants).

-   Ensures individual participant accountability.

-   Ties it all together for the participant.

-   Provides insight and experience to the learning process.

-   Effectively leads the whiteboard design session discussion.

-   Monitors quality and appropriateness of participant deliverables.

-   Effectively leads the feedback process.

## Whiteboard design session flow 

Each whiteboard design session uses the following flow:

**Step 1: Review the customer case study (15 minutes)**

Outcome: Analyze your customer's needs

-   Customer's background, situation, needs and technical requirements

-   Current customer infrastructure and architecture

-   Potential issues, objectives and blockers

**Step 2: Design a proof of concept solution (60 minutes)**

Outcome: Prepare to present a solution for your target customer audience

-   Determine your target customer audience

-   Determine customer's business needs to address your solution

-   Design and diagram your solution

-   Prepare to present your solution

**Step 3: Present the solution (30 minutes)**

Outcome: Present solution to your customer

-   Present solution

-   Respond to customer objections

-   Receive feedback

**Wrap-up (15 minutes)**

-   Review preferred solution

## Before the whiteboard design session: How to prepare

Before conducting your first whiteboard design session:

-   Read the Student guide (including the case study) and Trainer guide

-   Become familiar with all key points and activities.

-   Plan the point you want to stress, which questions you want to drive, transitions, and be ready to answer questions.

-   Prior to the whiteboard design session, discuss the case study to pick up more ideas.

-   Make notes for later.

## During the whiteboard design session: Tips for an effective whiteboard design session

**Refer to the Trainer guide** to stay on track and observe the timings.

**Do not expect to memorize every detail** of the whiteboard design session.

When participants are doing activities, you can **look ahead to refresh your memory**.

-   **Adjust activity and whiteboard design session pace** as needed to allow time for presenting, feedback, and sharing.

-   **Add examples, points, and stories** from your own experience. Think about stories you can share that help you make your points clearly and effectively.

-   **Consider creating a "parking lot"** to record issues or questions raised that are outside the scope of the whiteboard design session or can be answered later. Decide how you will address these issues, so you can acknowledge them without being derailed by them.

***Have fun**! Encourage participants to have fun and share!*

**Involve your participants.** Talk and share your knowledge but always involve your participants, even while you are the one speaking.

**Ask questions** and get them to share to fully involve your group in the learning process.

**Ask first**, whenever possible. Before launching into a topic, learn your audience's opinions about it and experiences with it. Asking first enables you to assess their level of knowledge and experience, and leaves them more open to what you are presenting.

**Wait for responses**. If you ask a question such as, "What's your experience with (fill in the blank)?" then wait. Do not be afraid of a little silence. If you leap into the silence, your participants will feel you are not serious about involving them and will become passive. Give participants a chance to think, and if no one answers, patiently ask again. You will usually get a response.

#  Intelligent vending machines whiteboard design session student guide

## Abstract and learning objectives 

In this workshop, attendees will implement an IoT solution for intelligent vending machines, leveraging facial feature recognition and Azure Machine Learning, to gain a better understanding of building cloud-based machine learning app, and real-time analytics with SQL Database in-memory and columnar indexing.

In addition, attendees will learn to:

-   Enable real-time analytics with SQL Database in-memory and columnar indexing

-   Implement distributed machine learning with R Server for HDInsight & Microsoft R Server Operationalization

-   Perform facial image processing

-   Wrangle data in Power BI Desktop

## Step 1: Review the customer case study 

**Outcome** 

Analyze your customer’s needs.
Time frame: 15 minutes 
Directions: With all participants in the session, the facilitator/SME presents an overview of the customer case study along with technical tips. 
1.  Meet your table participants and trainer 
2.  Read all of the directions for steps 1–3 in the student guide 
3.  As a table team, review the following customer case study

### Customer situation

Trey Research Inc. looks at the old way of doing things in retail, and introduces innovative experiences that delight customers and drive sales. Their latest initiative focuses on intelligent vending machines that have sophisticated computing platforms called Vending Machine IO boards (which are capable of running Microsoft Windows). These boards are well advanced beyond the traditional Vending Machine Controller (VMC) that are only capable of rudimentary functions like controlling temperature, dispensing product and processing cash payment. Each vending machine includes a large, hi-definition display, a touch screen, a camera, and peripherals for handling cash and credit cards, and they are all connected via either WIFI or 4G LTE connections to the Internet.

They work with chipset vendors and manufacturers to build the specialized units, so instead the bulk of their effort goes into the software and the platform that make the vending machines intelligent. In their current initiative they are looking at designing a solution that addresses three core areas: commerce, engagement analytics and intelligent promotions.

When it comes to commerce, they are looking at modernizing the handling of purchase transactions - their vending machines accept payment by cash or credit card, and in the future, may accept payment by Near Field Communication (NFC). When an item is purchased, a form of payment is captured (e.g., cash is inserted, or a credit card is inserted). In dealing with a cash payment, the currency received is verified at the vending machine. The currency is returned if not accepted and the purchase may be aborted by the consumer. Credit card payments require an additional step. They need to authorize and capture payment first via a 3rd party payment gateway. Again, the purchase may be aborted by the consumer if the credit card is declined. When the purchase transaction completes successfully, Trey needs to update their centralized inventory. This inventory, which describes what is in-stock for each vending machine, is adjusted down to reflect the item sold at that machine. Trey would like to ensure that regardless of the payment method or the transaction outcome, that all purchase transactions are logged to a database for later analysis.

While commerce is of prime importance, Trey Research believes that understanding the events that led to a successful or unsuccessful purchase transaction are just as important. They want to be able to collect Engagement Telemetry that includes dwell times, impressions and conversions. These are defined as follows:

-   Dwell Times: a user "session", for a given subject. Dwell times indicate how long the user either interacted with the device or stood by examining the inventory/promotions. These metrics have a start time and duration.

-   Impressions: the time and type of promotion displayed

-   Conversions: when a recommendation is displayed, and a purchase transaction occurred, was the recommended product purchased or not?

The goal being that the data that their vending machine provides can paint a picture of the purchase funnel---that is understanding what products were viewed in a session, which was ultimately purchased, and which was not?

The final piece of their Intelligent Vending Machine trifecta (as Grant Trey, their Chief Innovation Officer puts it) is Intelligent Promotion. Each vending machine maintains a local copy of the ads (images, videos) that are appropriate to the inventory and used with promotions. These are pushed as a package down to the vending machine on-demand. The vending machine gets a notification indicating new packages are available and then downloads them from the repository.

"It should be like being able to give the vending machine a new paint job with the click of a button", says Dan Cole their VP of Engineering.

New Packages are configured in the database (via a web-based portal) and are then scheduled for download by the vending machines. There is a website that is used to create new promotions and schedule them for downloading to machines.

With the advertisement and signage in place, Trey wants their vending machines to show off a little in the way it approaches promotions. A promotion selects a single product to feature by displaying its ad signage and presents it to the consumer with a discounted price, e.g. it is priced "Just-for-you". The way Trey Research envisions this, when a vending machine identifies a visitor in proximity, it takes a photo that it will use to anonymously determine demographics (such as age, gender, and possibly features like whether the consumer is smiling or wearing sunglasses) that are used to decide what to promote on its display. This photo is uploaded to a web service, which then uses face detection to extract demographics data about the consumer. The demographics are sent to a recommendation model that suggests a product and a price to promote and the recommended promotion is returned from the call to the web service. The vending machine then displays the recommended product at the recommended price. In addition to driving the recommendation, these demographics (but not the photos) are stored durably for later analysis and for re-training of the recommendation model.

Trey Research realizes that their vending machines and the cloud are a perfect match, and are looking for ways to build their solution using Microsoft Azure. They are particularly interested in how they can deploy scalable machine learning models. Today they expect their training data to be in the tens of GB, but they want to ensure they pick a solution that can get to terabyte scale if needed. Finally, they are also particularly keen on a tool that can help them quickly explore, wrangle and visualize their data either with desktop or web based interfaces. 

### Customer needs 

1.  An IoT solution that can handle high volumes of telemetry data, and enables the solution to communicate with the vending machines for situations like package updates.

2.  A data store that can handle the extremely write-heavy workload that results from the purchase transactions, whilst still allowing them to quickly perform analytics using SQL.

3.  A platform on which to build and train machine learning models against high volumes of training data, ideally programmed with R.

4.  A solution that can provide demographics, given a photo of a person.

5.  A highly scalable storage solution that won't "max out" and can handle all the telemetry from their vending machines.

6.  Tools for performing light-weight wrangling of their data, exploration and visualization.
 
### Customer objections 

1.  We've heard that Azure's machine learning can only train on data sets up to 10GB in size, are we blocked?

2.  While not required in the short term, would our machine learning approach enable us to support reinforcement learning (whereby recommendations that lead to a purchase are preferred over time)?

3.  Can we really perform real-time analytics using only a single data store? We cannot afford to lose any of our purchase transaction data.

4.  We are concerned that training our models will take too long.
  
### Infographic for common scenarios

![Screenshot of a sample Internet of Things workflow, which is broken into On-Premises and Azure services. At this time, we are unable to capture all of the information in the slide. Future versions of this course should address this.](images/Whiteboarddesignsessiontrainerguide-Intelligentvendingmachinesimages/media/image2.png "Common scenarios for Internet of Things")

## Step 2: Design a proof of concept solution

**Outcome** 
Design a solution and prepare to present the solution to the target customer audience in a 15-minute chalk-talk format. 

Time frame: 60 minutes

**Business needs**

Directions: With all participants at your table, answer the following questions and list the answers on a flip chart. 
1.  Who should you present this solution to? Who is your target customer audience? Who are the decision makers? 
2.  What customer business needs do you need to address with your solution?

**Design** 
Directions: With all participants at your table, respond to the following questions on a flip chart.

*High-level architecture*

1.  Without getting into the details (the following sections will address the details), diagram your initial vision for handling the top-level requirements for data loading, data preparation, storage, machine learning modeling, and reporting. You will refine this diagram as you proceed.

*Commerce*

1.  How would you recommend that Trey complete purchase transactions and store their purchase transaction history in Azure?

2.  What services would you suggest and how would configure the storage and indexing?

*Engagement analytics*

1.  What service would you recommend Trey capitalize on to scalably ingest the engagement telemetry directly from the vending machines?

2.  Would you recommend they use Azure Storage or Azure Data Lake Store for persisting their engagement telemetry? Be specific with your reasoning.

3.  What is processing the telemetry ingested, at least in so far as persisting the telemetry to the durable storage you recommended? How is this configured or implemented?

*Facial demographics*

1.  What Azure service or API would you suggest Trey utilize for determining demographics about a consumer from a photo of them taken by the vending machine?

*Intelligent promotions*

1.  What technology would you recommend that Trey use for implementing their machine learning model that recommends a product and price given consumer demographics?

2.  How would you guide Trey to load data, so it can be used for training the machine learning model?

3.  What category of machine learning algorithm would you recommend to Trey for use in constructing their model? For this scenario, your options are: clustering, regression or two-class classification. Why?

4.  Are there any R packages you would suggest they utilize?

5.  How would you operationalize your trained model, so it can be invoked with the demographics?

6.  Where would you store the packages containing promotional artifacts for download by the vending machine and how would you instruct the vending machine to download and install them? Be specific on any Azure services and protocols used.

*Visualization and reporting*

1.  What tool would you recommend Trey utilize for performing ad-hoc wrangling, exploration and visualization of their data?

2.  How would you make the resulting visualization available to others in the organization?

**Prepare**

Directions: With all participants at your table: 

1.  Identify any customer needs that are not addressed with the proposed solution. 
2.  Identify the benefits of your solution. 
3.  Determine how you will respond to the customer’s objections. 

Prepare a 15-minute chalk-talk style presentation to the customer. 


## Step 3: Present the solution

**Outcome**
 
Present a solution to the target customer audience in a 15-minute chalk-talk format.

Time frame: 30 minutes

**Presentation** 

Directions:
1.  Pair with another table.
2.  One table is the Microsoft team and the other table is the customer.
3.  The Microsoft team presents their proposed solution to the customer.
4.  The customer makes one of the objections from the list of objections.
5.  The Microsoft team responds to the objection.
6.  The customer team gives feedback to the Microsoft team. 
7.  Tables switch roles and repeat Steps 2–6.

##  Additional references

|    |            |
|----------|:-------------:|
| **Description** | **Links** |
| Infographic | <http://bit.ly/1kRTbiO/> |
| Machine Learning | <https://azure.microsoft.com/documentation/articles/machine-learning-algorithm-choice/> |
| Real-time Analytics | <https://msdn.microsoft.com/library/dn817827.aspx/> |
| R Server on HDInsight | <https://azure.microsoft.com/documentation/articles/hdinsight-hadoop-r-server-overview/> |
| Power BI | <https://powerbi.microsoft.com/en-us/what-is-power-bi/> |
|

# Intelligent vending machines whiteboard design session trainer guide

## Step 1: Review the customer case study

-   Check in with your table participants to introduce yourself as the trainer.

-   Ask, "What questions do you have about the customer case study?"

-   Briefly review the steps and timeframes of the whiteboard design session.

-   Ready, set, go! Let the table participants begin.

## Step 2: Design a proof of concept solution

-   Check in with your tables to ensure that they are transitioning from step to step on time.

-   Provide some feedback on their responses to the business needs and design.

    -   Try asking questions first that will lead the participants to discover the answers on their own.

-   Provide feedback for their responses to the customer's objections.

    -   Try asking questions first that will lead the participants to discover the answers on their own.

## Step 3: Present the solution

-   Determine which table will be paired with your table before Step 3 begins.

-   For the first round, assign one table as the Microsoft team and the other table as the customer.

-   Have the Microsoft team present their solution to the customer team.

    -   Have the customer team provide one objection for the Microsoft team to respond to.

    -   The presentation and objections should be no longer than 10 minutes.

-   Have participants on the customer team give feedback to the Microsoft team.

    -   The feedback should be no longer than 5 minutes.

    -   If needed, the trainer may also provide feedback.

## Wrap-up

-   Have the table participants reconvene with the larger session group to hear a SME share the following preferred solution.

##  Preferred target audience

Grant Trey, Chief Innovation Officer, Trey Research

Dan Cole, VP of Engineering, Trey Research

The primary audience is the business decision makers and technology decision makers. From the case study scenario, this would include the Director of Analytics. Usually we talk to the infrastructure managers who report to the chief information officers (CIOs), or to application sponsors (like a vice president \[VP\] line of business \[LOB\], or chief marketing officer \[CMO\]), or to those that represent the business unit IT or developers that report to application sponsors.

## Preferred solution

*High-level architecture*

1.  Without getting into the details (the following sections will address the details), diagram your initial vision for handling the top-level requirements for data loading, data preparation, storage, machine learning modeling, and reporting. You will refine this diagram as you proceed.

The high-level view of the entire solution appears as follows.

![Diagram of the preferred solution. From a high-level, the commerce solution uses an API App to host the Payments web service with which the Vending Machine interacts to conduct purchase transactions. The Payment Web API invokes a 3rd party payment gateway as needed for authorizing and capturing credit card payments, and logs the purchase transaction to SQL DB. The data for these purchase transactions is stored using an In-Memory table with a Columnar Index, which will support the write-heavy workload while still allowing analytics to operate, such as queries coming from Power BI Desktop.](images/Whiteboarddesignsessiontrainerguide-Intelligentvendingmachinesimages/media/image3.png "Preferred high-level architecture")\
It is easier to understand the solution by looking at the individual flows for each of commerce, engagement telemetry and intelligent promotions.

The commerce solution, as illustrated below, uses an API App to host the Payments web service with which the Vending Machine interacts to conduct purchase transactions. The Payment Web API invokes a 3rd party payment gateway as needed for authorizing and capturing credit card payments, and logs the purchase transaction to SQL DB. The data for purchase transactions in SQL DB is stored using an In-Memory table with a Columnar Index, which will support the write-heavy workload while still allowing analytics to operate, such as queries coming from Power BI Desktop.

![The Commerce solution diagram begins with an API App (payments web API) icon, which is the third Party Payment gateway. One arrow labeled \"purchase transactions\" points from API App to a Vending Machine icon. A second arrow labeled \"payent instrument item purchased purchase price\" points from API App to a SQL (Real-time analytics) icon. A Power BI Desktop icon also has an arrow pointing to the SQL Real-time Analytics) icon.](images/Whiteboarddesignsessiontrainerguide-Intelligentvendingmachinesimages/media/image4.png "Commerce solution diagram")

The engagement telemetry solution uses IoT Hub to ingest and temporarily store telemetry data from the vending machine. A Web Job (or Stream Analytics) is used to pull the telemetry messages from IoT Hub and archive them in Azure Data Lake Store. New promotion packages are pushed from the Web App hosting the promotion management portal website to Blob storage. A SAS URL is generated to the promotion package intended for the vending machine and sent to the vending machine via IoT Hub cloud to device messaging. The vending machine receives the message, and then downloads the new promotion package from Blob Storage.

![The Engagement telemetry solution diagram includes an IoT hub, with arrows pointing from it to icons representing a Vending Machine, Web App, Blob Storage, Web Job, and Data Lake Store.](images/Whiteboarddesignsessiontrainerguide-Intelligentvendingmachinesimages/media/image5.png "Engagement telemetry solution")

The intelligent promotions solution begins when a customer walks up to a vending machine. The machine takes a picture of the customer and sends it to a web service hosted in an API App. The API App integrates the Face API to acquire the demographics of the person in the photo. It can then invoke the dynamic pricing machine learning model hosted either in Azure ML or in Microsoft R Server Operationalization, to get the recommended product and price. Finally, all computed demographics and recommendations should be stored to Azure Data Lake to be able to improve the training of the Machine Learning model built with R and trained on R Server on HDInsight.

![Screenshot of an Intelligent promotions solution diagram, which includes API App, Blob Storage, ML Model, RServer on HDInsight, Data Lake Store, and Face API. At this time, we are unable to capture all of the information in the diagram. Future versions of this course should address this.](images/Whiteboarddesignsessiontrainerguide-Intelligentvendingmachinesimages/media/image6.png "Intelligent promotions solution")

**NOTE**: The preferred solution is only one of many possible, viable approaches.

*Commerce*

1.  How would you recommend that Trey complete purchase transactions and store their purchase transaction history in Azure?
    
    Trey research should provision an API App that will host the web service responsible for payments. This API app can examine the payment instrument used in the purchase transaction. If the payment instrument is credit card, it should make a call out to the 3rd party payment gateway to authorize and capture payment. If the credit card payment is successful or the payment instrument is cash, then the successful transaction should then be captured in Azure SQL Database, as well as a success result returned to the vending machine to dispense the product. In the case of a transaction aborted at the vending machine (e.g., because the currency provided was rejected) a transaction with an aborted status should be sent from the vending machine and logged. In the case when the credit card is declined by the payment gateway, a card declined result should be returned to the vending machine and allow the consumer to either enter a different form of payment (e.g., cash or a different credit card) or to abort the transaction.

2.  What services would you suggest and how would configure the storage and indexing? Be specific.
    
    To support the write-heavy workload that results from storing successful and aborted transactions, Trey should configure the transactions table as an In-Memory table with a Non-Clustered Columnar Index. The In-Memory (memory-optimized) table is configured with durability of SCHEMA\_AND\_DATA, enabling the benefit of supporting large numbers of insert queries without the risk of losing data because it provides fully durable transactions that write the transaction log to disk before returning control to the client.
    
    The primary key on this table would be an identity column using a Hash index (enabling fast point lookups for specific transactions whilst still allowing for fast row inserts).
    
    The Non-Clustered Columnar Index would be configured on all the columns. The effect of this is that the columnstore index maintains a copy of the data, enabling OLTP and analytics workloads to run against separate copies of the data. To leverage the memory-optimized features, Trey would need to deploy the Premium tier of Azure SQL Database.

*Engagement analytics*

1.  What service would you recommend Trey capitalize on in order to scalably ingest the engagement telemetry directly from the vending machines?
    
    Trey should use IoT hubs to initially ingest and temporarily store engagement telemetry from the vending machines. While Event Hubs could also be utilized for this purpose, the requirement to send commands to the vending machine to support intelligent promotions would only be supported by IoT Hubs (since it provides functionality for both device-to-cloud and cloud-to-device messaging).

2.  Would you recommend they use Azure Storage Blobs or Azure Data Lake Store for persisting their engagement telemetry? Be specific with your reasoning.
    
    Trey should consider using Azure Data Lake Store because it addresses their concern of "maxing out" their storage capacity. Unlike Azure Storage Blobs (which has a maximum capacity of 500 TB) per account, Azure Data Lake Store has no fixed upper limits and scales as Trey's storage needs scale. To accomplish a similar goal with Azure Storage would mean provisioning new Azure Storage accounts each time the limit is approached, and managing the storage of the data across multiple Azure Storage accounts.

3.  What is processing the telemetry ingested, at least in so far as persisting the telemetry to the durable storage you recommended? How is this configured or implemented?
    
    Given that the scenario specified no additional processing on the ingested telemetry other than to store it, the simplest option would be to configure an Azure Stream Analytics job to pull the data from IoT Hub and configure the Data Lake Store as the stream output. While this approach requires no code, it currently comes with a potential challenge for Trey. That is, every 90 days the authorization for Stream Analytics to access Azure Data Lake Store needs to be renewed. To renew the authorization will require Trey to stop their Stream Analytics job, renew the authorization and restart it. This, of course, would stop the flow of telemetry from the vending machines to storage temporarily (although no telemetry would be list as it would simply collect in the IoT Hub queue). If this is a concern for Trey, they could instead use a Web Job that is running the Event Processor Host (from the Service Bus SDK), and implement an Event Processor that uses the Azure Data Lake Store SDK to write the telemetry pulled from IoT Hub.

*Facial demographics*

1.  What Azure service or API would you suggest Trey utilize for determining demographics about a consumer from a photo of them taken by the vending machine? How is this provisioned and utilized?
    
    Trey can utilize the Face API, a part of Microsoft Cognitive Services. The Face API exposes a Face Detect operation that, provided a URL to photo, returns demographics about the subject of the photo including features such as age, gender, facial expression, facial hair, head position and if any form of glasses (reading, sunglasses, swim goggles, etc.) are detected. To accomplish this, Trey would need to provision a Cognitive Services account with an API type of Face API in the Portal. They would also need to provision an API App that would receive the photo from the vending machine, temporarily store it in Blob storage, and provide the URL (using a SAS token) to the Face API. Once the demographics have been retrieved from the Face API, the API App can delete the photo from blob storage to preserve anonymity.

*Intelligent promotions*

1.  What technology would you recommend that Trey use for implementing their machine learning model that recommends a product and price given consumer demographics?
    
    Given Trey's concern about training datasets in the 10's of GB, you should first check that they really do need those large datasets to accurately train their model---in many cases very high accuracy can be achieved with datasets many times smaller, so it is important to involve a Data Scientist to verify this concern. If large training data sets are required, Azure Machine Learning cannot be used (since the maximum dataset size it can access is 10GB). Instead, Trey should look at running R Server on HDInsight. This would enable them to program their machine learning models in R, but also be able to address large training data sets as well as reducing training time by being able to parallelize the training across multiple nodes in a cluster.

2.  How would you guide Trey to load data, so it can be used for training the machine learning model?
    
    Trey should be capturing the telemetry to Azure Data Lake Store, which can be accessed from R Server on HDInsight.

3.  What category of machine learning algorithm would you recommend to Trey for use in constructing their model? For this scenario your options are clustering, regression or two-class classification. Why?
    
    Trey could implement their model using linear regression that would center around predicting the price at which to sell the items in the inventory of the vending machine, given the product and the demographics. A second model could be used that implements a two-class classification (sold or not sold) that predicts which product is likely to be bought given the product, demographics and recommended price.

4.  How would you operationalize your trained model, so it can be invoked with the demographics?

    They should expose the trained model as a web service. One possible approach is to leverage Azure Machine Learning to host the trained model as a scoring service. To score by using an Azure Machine Learning web service, Trey could use the open source Azure Machine Learning R package to publish their model as an Azure web service. They would use the features of Azure Machine Learning to create an interface for the web service, and then call the web service as needed for scoring.

    There is one caveat with this approach- Trey would need to convert any ScaleR model objects to equivalent open-source model objects for use with the web service. This can be done through the use of ScaleR coercion functions, such as as.randomForest() for ensemble-based models. By doing this, Trey would be forgoing the scale out capabilities of the ScaleR objects.

    To maintain the scale out capabilities, Trey could provision a server running Microsoft R Server Operationalization, which would enable them to deploy their R scripts and models as a web service. These web services can run models built with ScaleR functions and therefore Trey would not need to sacrifice the scale-out training capability in order to achieve easy operationalization into web services.

5.  Where would you store the packages containing promotional artifacts for download by the vending machine and how would you instruct the vending machine to download and install them? Be specific on any Azure services used.

    The packages could be stored in Blob storage. A SAS signature could be generated that the vending machine would use to download the package. This SAS URI would be provided by sending a command to the specific vending machine using IoT Hub.

*Visualization and reporting*

1.  What tool would you recommend Trey utilize for performing ad-hoc wrangling, exploration and visualization of their data?
    
    They could use Power BI Desktop. The Query Editor functionality would enable them to filter and shape the data before visualizing it in reports and creating dashboards.

2.  How would you make the resulting visualization available to others in the organization?
    
    They can publish their reports to PowerBI.com.

## Checklist of preferred objection handling

*We've heard that Azure's machine learning can only train on data sets up to 10GB in size, are we blocked?*

While this is true for datasets processed using Azure Machine Learning, this is not the case in Azure when using R Server, either on HDInsight or as SQL Server R Services with SQL Server in a VM.

*While not required in the short term, would our machine learning approach enable us to support reinforcement learning (whereby recommendations that lead to a purchase are preferred over time)?*

Reinforcement learning requires a training loop that feeds successful predictions back into the model to improve. Azure Machine Learning does not support this, but there are various R learners (that can run on R Server on HDInsight) that support reinforcement.

*Can we really perform real-time analytics using only a single data store? We cannot afford to lose any of our purchase transaction data.*

Yes. Real-time analytics in SQL Server 2016 and Azure SQL Database is an approach that aims to provide support for analytics workloads (e.g., queries that compute aggregates over large portions of a dataset) while not affecting the performance or durability of transactional workloads (e.g., those that are write/query intensive). This is accomplished with the In-Memory and Columnar Index features.

*We are concerned that training our models will take too long.*

Azure Machine Learning currently uses a single A8 virtual machine instance to train a model and does not utilize algorithms that parallelize across cores. R Server on HDInsight provides specialized algorithms that parallelize across server cores and across nodes in the HDInsight cluster. SQL Server R Services does not currently parallelize training across servers in a cluster.

## Customer quote (to be read back to the attendees at the end)

"We are predicting a future full of intelligent vending machines, thanks to Azure."

Grant Trey, Chief Innovation Officer, Trey Research

